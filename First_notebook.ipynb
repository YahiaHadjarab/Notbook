{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cf729d-a275-4318-96c9-e5b53faa9cbc",
   "metadata": {},
   "source": [
    "# My first notbook\n",
    "\n",
    "# Jupyter Notebook Introduction\n",
    "\n",
    "## What is Jupyter Notebook?\n",
    "\n",
    "Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text. It's widely used for data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Interactive Coding**: Code can be written in cells, allowing for interactive development and testing.\n",
    "- **Support for Multiple Languages**: Primarily supports Python, but with kernels for R, Julia, and over 100 other languages.\n",
    "- **Rich Media Support**: Incorporate equations, images, videos, and HTML widgets directly into your notebooks.\n",
    "- **Data Visualization**: Integrated with libraries such as Matplotlib and Seaborn for impactful data visualizations.\n",
    "- **Sharing**: Notebooks can be shared easily with others, facilitating collaboration.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "1. **Installation**: Install Jupyter Notebook via Anaconda (recommended for beginners) or pip.\n",
    "\n",
    "2. **Launching Jupyter Notebook**:\n",
    "- Open your terminal or command prompt.\n",
    "- Run the command `jupyter notebook`.\n",
    "- Your default web browser will open a new tab displaying the Jupyter Dashboard.\n",
    "3. **Creating a New Notebook**: Click on the \"New\" button at the top right corner and select your desired programming language.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Jupyter Notebook is a powerful tool for interactive computing. It simplifies the process of data analysis, ensuring that your work is not only reproducible but also shareable. Start exploring Jupyter Notebook today and unlock the potential of your data!\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "...\n",
    "\n",
    "## Module load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4ea563-3023-4e20-a8d9-3a4e616a6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "module load zenodo_get/1.3.2\n",
    "module load hisat2/2.2.1\n",
    "module load fastqc/0.12.1\n",
    "module load samtools/1.15.1\n",
    "module load htseq/0.13.5\n",
    "module load r/4.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375669a-388f-4955-b64f-2576cf61f4c9",
   "metadata": {},
   "source": [
    "# Get Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c03400a-c848-4d9d-bb13-bce8f6469c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: reduced RNAseq for FAIR_Bioinfo courses\n",
      "Keywords: \n",
      "Publication date: 2020-08-24\n",
      "DOI: 10.5281/zenodo.3997237\n",
      "Total size: 118.8 MB\n",
      "\n",
      "Link: https://zenodo.org/api/records/3997237/files/FAIR_Bioinfo_data.tar.gz/content   size: 118.8 MB\n",
      " 19% [.........                                         ]  24502272 / 124534911\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49% [........................                          ]  61120512 / 124534911\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78% [.......................................           ]  97615872 / 124534911\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..................................................] 124534911 / 124534911\n",
      "Checksum is correct. (85db07129cd29f353fed6c547f5ed4b1)\n",
      "All files have been downloaded.\n"
     ]
    }
   ],
   "source": [
    "zenodo_get -t 60 -R 3 10.5281/zenodo.3997237"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e507f1-904b-4b4e-b1c9-91a3d50623a8",
   "metadata": {},
   "source": [
    "### Checking the viability of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9e0c00-c626-4def-9a4a-f674b170e73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIR_Bioinfo_data.tar.gz: OK\n"
     ]
    }
   ],
   "source": [
    "md5sum -c md5sums.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa7f0c9-e963-47a2-84a4-84f584d4bf6a",
   "metadata": {},
   "source": [
    "### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54841559-7b9e-4573-b68a-8ed5cb2be4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar -xzf FAIR_Bioinfo_data.tar.gz && rm FAIR_Bioinfo_data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860a04e-4a5b-4bc6-8d16-e1339fba5ab4",
   "metadata": {},
   "source": [
    "## Create hisat2 indexes\n",
    "\n",
    "### The tool used : `hisat2-build`\n",
    "\n",
    "The `hisat2-build` command is used in bioinformatics to index a reference genome for efficient alignment of sequence reads. Here's what it does:\n",
    "\n",
    "1. **Reference Genome Indexing:** Takes a reference genome, divides it into small parts, and creates an index.\n",
    "   \n",
    "2. **Partitioning into Small Parts:** Divides the reference genome into fragments of a certain size.\n",
    "\n",
    "3. **Creating an Index:** Generates an index, which acts as a map or guide for quick retrieval of different genome parts. This index includes information about the positions of unique sequences in the genome.\n",
    "\n",
    "4. **Optimizing Search:** The created index speeds up the alignment process by allowing quick location of relevant genome regions, saving time especially when analyzing large datasets.\n",
    "\n",
    "In summary, `hisat2-build` creates an index from a reference genome, facilitating rapid alignment of sequence data during genetic analysis.\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f80977a-fde8-4f3a-8410-12cf1ebbe5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      "  Output files: \"hisat2_indexes/Otauri.*.ht2\"\n",
      "  Line rate: 6 (line is 64 bytes)\n",
      "  Lines per side: 1 (side is 64 bytes)\n",
      "  Offset rate: 4 (one in 16)\n",
      "  FTable chars: 10\n",
      "  Strings: unpacked\n",
      "  Local offset rate: 3 (one in 8)\n",
      "  Local fTable chars: 6\n",
      "  Local sequence length: 57344\n",
      "  Local sequence overlap between two consecutive indexes: 1024\n",
      "  Endianness: little\n",
      "  Actual local endianness: little\n",
      "  Sanity checking: disabled\n",
      "  Assertions: disabled\n",
      "  Random seed: 0\n",
      "  Sizeofs: void*:8, int:4, long:8, size_t:8\n",
      "Input files DNA, FASTA:\n",
      "  Data/O.tauri_genome.fna\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:00\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "  Time to read SNPs and splice sites: 00:00:00\n",
      "Using parameters --bmax 2441854 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 2441854 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:00\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:00\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:01\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 1.6279e+06 (target: 2441853)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering GFM loop\n",
      "Getting block 1 of 8\n",
      "  Reserving size (2441854) for bucket 1\n",
      "  Calculating Z arrays for bucket 1\n",
      "  Entering block accumulator loop for bucket 1:\n",
      "  bucket 1: 10%\n",
      "  bucket 1: 20%\n",
      "  bucket 1: 30%\n",
      "  bucket 1: 40%\n",
      "  bucket 1: 50%\n",
      "  bucket 1: 60%\n",
      "  bucket 1: 70%\n",
      "  bucket 1: 80%\n",
      "  bucket 1: 90%\n",
      "  bucket 1: 100%\n",
      "  Sorting block of length 1195229 for bucket 1\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 1195230 for bucket 1\n",
      "Getting block 2 of 8\n",
      "  Reserving size (2441854) for bucket 2\n",
      "  Calculating Z arrays for bucket 2\n",
      "  Entering block accumulator loop for bucket 2:\n",
      "  bucket 2: 10%\n",
      "  bucket 2: 20%\n",
      "  bucket 2: 30%\n",
      "  bucket 2: 40%\n",
      "  bucket 2: 50%\n",
      "  bucket 2: 60%\n",
      "  bucket 2: 70%\n",
      "  bucket 2: 80%\n",
      "  bucket 2: 90%\n",
      "  bucket 2: 100%\n",
      "  Sorting block of length 1294025 for bucket 2\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 1294026 for bucket 2\n",
      "Getting block 3 of 8\n",
      "  Reserving size (2441854) for bucket 3\n",
      "  Calculating Z arrays for bucket 3\n",
      "  Entering block accumulator loop for bucket 3:\n",
      "  bucket 3: 10%\n",
      "  bucket 3: 20%\n",
      "  bucket 3: 30%\n",
      "  bucket 3: 40%\n",
      "  bucket 3: 50%\n",
      "  bucket 3: 60%\n",
      "  bucket 3: 70%\n",
      "  bucket 3: 80%\n",
      "  bucket 3: 90%\n",
      "  bucket 3: 100%\n",
      "  Sorting block of length 1789994 for bucket 3\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 1789995 for bucket 3\n",
      "Getting block 4 of 8\n",
      "  Reserving size (2441854) for bucket 4\n",
      "  Calculating Z arrays for bucket 4\n",
      "  Entering block accumulator loop for bucket 4:\n",
      "  bucket 4: 10%\n",
      "  bucket 4: 20%\n",
      "  bucket 4: 30%\n",
      "  bucket 4: 40%\n",
      "  bucket 4: 50%\n",
      "  bucket 4: 60%\n",
      "  bucket 4: 70%\n",
      "  bucket 4: 80%\n",
      "  bucket 4: 90%\n",
      "  bucket 4: 100%\n",
      "  Sorting block of length 1920036 for bucket 4\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 1920037 for bucket 4\n",
      "Getting block 5 of 8\n",
      "  Reserving size (2441854) for bucket 5\n",
      "  Calculating Z arrays for bucket 5\n",
      "  Entering block accumulator loop for bucket 5:\n",
      "  bucket 5: 10%\n",
      "  bucket 5: 20%\n",
      "  bucket 5: 30%\n",
      "  bucket 5: 40%\n",
      "  bucket 5: 50%\n",
      "  bucket 5: 60%\n",
      "  bucket 5: 70%\n",
      "  bucket 5: 80%\n",
      "  bucket 5: 90%\n",
      "  bucket 5: 100%\n",
      "  Sorting block of length 1891077 for bucket 5\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 1891078 for bucket 5\n",
      "Getting block 6 of 8\n",
      "  Reserving size (2441854) for bucket 6\n",
      "  Calculating Z arrays for bucket 6\n",
      "  Entering block accumulator loop for bucket 6:\n",
      "  bucket 6: 10%\n",
      "  bucket 6: 20%\n",
      "  bucket 6: 30%\n",
      "  bucket 6: 40%\n",
      "  bucket 6: 50%\n",
      "  bucket 6: 60%\n",
      "  bucket 6: 70%\n",
      "  bucket 6: 80%\n",
      "  bucket 6: 90%\n",
      "  bucket 6: 100%\n",
      "  Sorting block of length 1964650 for bucket 6\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 1964651 for bucket 6\n",
      "Getting block 7 of 8\n",
      "  Reserving size (2441854) for bucket 7\n",
      "  Calculating Z arrays for bucket 7\n",
      "  Entering block accumulator loop for bucket 7:\n",
      "  bucket 7: 10%\n",
      "  bucket 7: 20%\n",
      "  bucket 7: 30%\n",
      "  bucket 7: 40%\n",
      "  bucket 7: 50%\n",
      "  bucket 7: 60%\n",
      "  bucket 7: 70%\n",
      "  bucket 7: 80%\n",
      "  bucket 7: 90%\n",
      "  bucket 7: 100%\n",
      "  Sorting block of length 1697345 for bucket 7\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 1697346 for bucket 7\n",
      "Getting block 8 of 8\n",
      "  Reserving size (2441854) for bucket 8\n",
      "  Calculating Z arrays for bucket 8\n",
      "  Entering block accumulator loop for bucket 8:\n",
      "  bucket 8: 10%\n",
      "  bucket 8: 20%\n",
      "  bucket 8: 30%\n",
      "  bucket 8: 40%\n",
      "  bucket 8: 50%\n",
      "  bucket 8: 60%\n",
      "  bucket 8: 70%\n",
      "  bucket 8: 80%\n",
      "  bucket 8: 90%\n",
      "  bucket 8: 100%\n",
      "  Sorting block of length 1270858 for bucket 8\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:00\n",
      "Returning block of 1270859 for bucket 8\n",
      "Exited GFM loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 2655580\n",
      "fchr[G]: 6510605\n",
      "fchr[T]: 10365900\n",
      "fchr[$]: 13023221\n",
      "Exiting GFM::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 8544067 bytes to primary GFM file: hisat2_indexes/Otauri.1.ht2\n",
      "Wrote 3255812 bytes to secondary GFM file: hisat2_indexes/Otauri.2.ht2\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from GFM constructor\n",
      "Returning from initFromVector\n",
      "Wrote 5793245 bytes to primary GFM file: hisat2_indexes/Otauri.5.ht2\n",
      "Wrote 3312424 bytes to secondary GFM file: hisat2_indexes/Otauri.6.ht2\n",
      "Re-opening _in5 and _in5 as input streams\n",
      "Returning from HGFM constructor\n",
      "Headers:\n",
      "    len: 13023221\n",
      "    gbwtLen: 13023222\n",
      "    nodes: 13023222\n",
      "    sz: 3255806\n",
      "    gbwtSz: 3255806\n",
      "    lineRate: 6\n",
      "    offRate: 4\n",
      "    offMask: 0xfffffff0\n",
      "    ftabChars: 10\n",
      "    eftabLen: 0\n",
      "    eftabSz: 0\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 813952\n",
      "    offsSz: 3255808\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideGbwtSz: 48\n",
      "    sideGbwtLen: 192\n",
      "    numSides: 67830\n",
      "    numLines: 67830\n",
      "    gbwtTotLen: 4341120\n",
      "    gbwtTotSz: 4341120\n",
      "    reverse: 0\n",
      "    linearFM: Yes\n",
      "Total time for call to driver() for forward index: 00:00:05\n"
     ]
    }
   ],
   "source": [
    "mkdir -p hisat2_indexes\n",
    "hisat2-build Data/O.tauri_genome.fna hisat2_indexes/Otauri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2df79-6525-4dfb-8a58-7071b5255e3d",
   "metadata": {},
   "source": [
    "## Check quality of the data\n",
    "\n",
    "### The tool used : `fastqc`\n",
    "\n",
    "The `fastqc` command is used in bioinformatics for quality control analysis of high-throughput sequencing data. Here's a brief overview of its functionality:\n",
    "\n",
    "1. **Quality Control Analysis:** FastQC analyzes the quality of sequencing data to identify potential issues or biases that may affect downstream analysis.\n",
    "\n",
    "2. **Input Data:** Takes input files in various formats (e.g., FASTQ) containing sequencing reads generated from experiments like RNA-seq, ChIP-seq, or whole-genome sequencing.\n",
    "\n",
    "3. **Analysis Modules:** FastQC performs various analysis modules to assess different aspects of data quality, including per-base sequence quality, per-sequence quality scores, sequence length distribution, GC content, sequence duplication levels, and overrepresented sequences.\n",
    "\n",
    "4. **Visual Reports:** Generates HTML reports containing summary statistics, graphs, and charts to visualize the quality metrics and identify any anomalies or patterns in the data.\n",
    "\n",
    "5. **Interpretation:** Users can interpret the FastQC reports to make informed decisions about data preprocessing steps, such as trimming adapters, filtering low-quality reads, or adjusting sequencing parameters.\n",
    "\n",
    "In summary, `fastqc` is a versatile tool for assessing the quality of sequencing data, providing valuable insights to researchers for optimizing experimental protocols and ensuring the reliability of downstream analyses.\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9a46f4-964e-4abc-9f6a-6ca09310f23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "Failed to process Data/O.tauri_annotation.gff\n",
      "uk.ac.babraham.FastQC.Sequence.SequenceFormatException: ID line didn't start with '@' at line 1\n",
      "\tat uk.ac.babraham.FastQC.Sequence.FastQFile.readNext(FastQFile.java:163)\n",
      "\tat uk.ac.babraham.FastQC.Sequence.FastQFile.<init>(FastQFile.java:93)\n",
      "\tat uk.ac.babraham.FastQC.Sequence.SequenceFactory.getSequenceFile(SequenceFactory.java:106)\n",
      "\tat uk.ac.babraham.FastQC.Sequence.SequenceFactory.getSequenceFile(SequenceFactory.java:62)\n",
      "\tat uk.ac.babraham.FastQC.Analysis.OfflineRunner.processFile(OfflineRunner.java:163)\n",
      "\tat uk.ac.babraham.FastQC.Analysis.OfflineRunner.<init>(OfflineRunner.java:125)\n",
      "\tat uk.ac.babraham.FastQC.FastQCApplication.main(FastQCApplication.java:316)\n",
      "null\n",
      "Failed to process Data/O.tauri_genome.fna\n",
      "uk.ac.babraham.FastQC.Sequence.SequenceFormatException: ID line didn't start with '@' at line 1\n",
      "\tat uk.ac.babraham.FastQC.Sequence.FastQFile.readNext(FastQFile.java:163)\n",
      "\tat uk.ac.babraham.FastQC.Sequence.FastQFile.<init>(FastQFile.java:93)\n",
      "\tat uk.ac.babraham.FastQC.Sequence.SequenceFactory.getSequenceFile(SequenceFactory.java:106)\n",
      "\tat uk.ac.babraham.FastQC.Sequence.SequenceFactory.getSequenceFile(SequenceFactory.java:62)\n",
      "\tat uk.ac.babraham.FastQC.Analysis.OfflineRunner.processFile(OfflineRunner.java:163)\n",
      "\tat uk.ac.babraham.FastQC.Analysis.OfflineRunner.<init>(OfflineRunner.java:125)\n",
      "\tat uk.ac.babraham.FastQC.FastQCApplication.main(FastQCApplication.java:316)\n",
      "application/gzip\n",
      "application/gzip\n",
      "Started analysis of SRR3099585_chr18.fastq.gz\n",
      "application/gzip\n",
      "application/gzip\n",
      "application/gzip\n",
      "application/gzip\n",
      "Approx 5% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3099585_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3099585_chr18.fastq.gz\n",
      "Analysis complete for SRR3099585_chr18.fastq.gz\n",
      "Started analysis of SRR3099586_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3099586_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3099586_chr18.fastq.gz\n",
      "Analysis complete for SRR3099586_chr18.fastq.gz\n",
      "Started analysis of SRR3099587_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3099587_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3099587_chr18.fastq.gz\n",
      "Analysis complete for SRR3099587_chr18.fastq.gz\n",
      "Started analysis of SRR3105697_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3105697_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3105697_chr18.fastq.gz\n",
      "Analysis complete for SRR3105697_chr18.fastq.gz\n",
      "Started analysis of SRR3105698_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3105698_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3105698_chr18.fastq.gz\n",
      "Analysis complete for SRR3105698_chr18.fastq.gz\n",
      "Started analysis of SRR3105699_chr18.fastq.gz\n",
      "Approx 5% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 10% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 15% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 20% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 25% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 30% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 35% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 40% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 45% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 50% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 55% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 60% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 65% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 70% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 75% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 80% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 85% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 90% complete for SRR3105699_chr18.fastq.gz\n",
      "Approx 95% complete for SRR3105699_chr18.fastq.gz\n",
      "Analysis complete for SRR3105699_chr18.fastq.gz\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "mkdir -p quality\n",
    "fastqc -o quality Data/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4098e8-c226-4878-b327-fe814741587b",
   "metadata": {},
   "source": [
    "## Align data to reference genome\n",
    "\n",
    "### The tools we use : `hisat2` & `samtools`\n",
    "\n",
    "#### Hisat2\n",
    "\n",
    "`hisat2` is a bioinformatics tool commonly used for aligning high-throughput sequencing reads to a reference genome. Here's a concise overview of its functionality:\n",
    "\n",
    "1. **Alignment of Sequencing Reads:** Hisat2 aligns sequencing reads, typically obtained from RNA-seq, DNA-seq, or other sequencing experiments, to a reference genome or transcriptome.\n",
    "\n",
    "2. **Input Data:** Accepts input reads in FASTQ format, which contain short sequences of nucleotides generated by sequencing machines.\n",
    "\n",
    "3. **Reference Genome Alignment:** Aligns reads to a reference genome or transcriptome to determine their genomic origin or mapping position.\n",
    "\n",
    "4. **Sensitive and Fast Alignment:** Hisat2 employs advanced algorithms to achieve highly sensitive and accurate alignments while maintaining computational efficiency, making it suitable for analyzing large-scale sequencing datasets.\n",
    "\n",
    "5. **Spliced Alignment:** Capable of accurately aligning reads across splice junctions in eukaryotic genomes, facilitating gene expression analysis from RNA-seq data.\n",
    "\n",
    "6. **Output Formats:** Generates alignment results in standard formats such as SAM (Sequence Alignment/Map) or BAM (Binary Alignment/Map), which can be further processed or visualized using various bioinformatics tools.\n",
    "\n",
    "7. **Compatibility:** Hisat2 is compatible with downstream analysis tools and pipelines commonly used in bioinformatics, allowing seamless integration into data analysis workflows.\n",
    "\n",
    "In summary, `hisat2` is a versatile and efficient tool for aligning sequencing reads to reference genomes or transcriptomes, providing essential information for various genomic and transcriptomic analyses.\n",
    "\n",
    "#### samtools\n",
    "\n",
    "`Samtools` is a versatile bioinformatics tool widely used for manipulating and analyzing files in the SAM (Sequence Alignment/Map) and BAM (Binary Alignment/Map) formats, which are commonly used to represent sequence alignments generated by various sequencing platforms. Here's a concise overview of its functionality:\n",
    "\n",
    "1. **File Format Conversion:** Samtools provides utilities for converting between SAM and BAM formats, enabling efficient storage and manipulation of alignment data.\n",
    "\n",
    "2. **Alignment Inspection:** Allows users to view and extract alignment information from SAM and BAM files, including read sequences, mapping quality scores, alignment positions, and alignment flags.\n",
    "\n",
    "3. **Sorting and Indexing:** Provides functions to sort alignment files by genomic coordinates and create index files for rapid retrieval of specific genomic regions, improving the efficiency of downstream analysis tasks.\n",
    "\n",
    "4. **Alignment Filtering:** Enables users to filter alignments based on various criteria such as mapping quality, read length, alignment flags, and alignment position, allowing for the selection of high-quality alignments for further analysis.\n",
    "\n",
    "5. **Pileup Generation:** Computes pileup information, summarizing the depth and variation of aligned reads at each genomic position, which is useful for variant calling and other genomic analyses.\n",
    "\n",
    "6. **Variant Calling:** Supports variant calling from aligned reads, providing tools for identifying single nucleotide polymorphisms (SNPs), insertions, deletions, and structural variants in genomic data.\n",
    "\n",
    "7. **Integration with Workflows:** Samtools can be seamlessly integrated into bioinformatics workflows, serving as a fundamental component for processing and analyzing high-throughput sequencing data.\n",
    "\n",
    "In summary, `samtools` is a powerful toolset for manipulating and analyzing sequence alignment data, providing essential functionalities for a wide range of bioinformatics applications.\n",
    "\n",
    "### Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7aacc9e-7d7c-4377-939e-364954e1b9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/SRR3099585_chr18.fastq.gz\n",
      "313471 reads; of these:\n",
      "  313471 (100.00%) were unpaired; of these:\n",
      "    4896 (1.56%) aligned 0 times\n",
      "    237803 (75.86%) aligned exactly 1 time\n",
      "    70772 (22.58%) aligned >1 times\n",
      "98.44% overall alignment rate\n",
      "Data/SRR3099586_chr18.fastq.gz\n",
      "252818 reads; of these:\n",
      "  252818 (100.00%) were unpaired; of these:\n",
      "    6101 (2.41%) aligned 0 times\n",
      "    211303 (83.58%) aligned exactly 1 time\n",
      "    35414 (14.01%) aligned >1 times\n",
      "97.59% overall alignment rate\n",
      "Data/SRR3099587_chr18.fastq.gz\n",
      "275225 reads; of these:\n",
      "  275225 (100.00%) were unpaired; of these:\n",
      "    6829 (2.48%) aligned 0 times\n",
      "    236283 (85.85%) aligned exactly 1 time\n",
      "    32113 (11.67%) aligned >1 times\n",
      "97.52% overall alignment rate\n",
      "Data/SRR3105697_chr18.fastq.gz\n",
      "252211 reads; of these:\n",
      "  252211 (100.00%) were unpaired; of these:\n",
      "    5865 (2.33%) aligned 0 times\n",
      "    222825 (88.35%) aligned exactly 1 time\n",
      "    23521 (9.33%) aligned >1 times\n",
      "97.67% overall alignment rate\n",
      "Data/SRR3105698_chr18.fastq.gz\n",
      "405603 reads; of these:\n",
      "  405603 (100.00%) were unpaired; of these:\n",
      "    8490 (2.09%) aligned 0 times\n",
      "    350508 (86.42%) aligned exactly 1 time\n",
      "    46605 (11.49%) aligned >1 times\n",
      "97.91% overall alignment rate\n",
      "Data/SRR3105699_chr18.fastq.gz\n",
      "235166 reads; of these:\n",
      "  235166 (100.00%) were unpaired; of these:\n",
      "    8099 (3.44%) aligned 0 times\n",
      "    204267 (86.86%) aligned exactly 1 time\n",
      "    22800 (9.70%) aligned >1 times\n",
      "96.56% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "mkdir -p hisat2\n",
    "for fq in Data/*.fastq.gz ; do\n",
    "    echo ${fq} \n",
    "    libname=$(basename $fq .fastq.gz)\n",
    "    hisat2 -x hisat2_indexes/Otauri -q -U ${fq} -S hisat2/${libname}.sam\n",
    "    samtools view -b -o hisat2/${libname}.bam hisat2/${libname}.sam\n",
    "    samtools sort -o hisat2/${libname}-sort.bam hisat2/${libname}.bam\n",
    "    samtools index hisat2/${libname}-sort.bam\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0530ad-a699-4bff-9115-bf547627ed88",
   "metadata": {},
   "source": [
    "## Count number of reads per gene\n",
    "\n",
    "### The tool we use : `htseq-count`\n",
    "\n",
    "The `htseq-count` tool is used in bioinformatics for quantifying gene expression from RNA sequencing (RNA-seq) data. Here's a brief overview of its functionality:\n",
    "\n",
    "1. **Counting Reads:** `htseq-count` counts the number of sequencing reads that align to features such as genes or exons in a reference genome.\n",
    "\n",
    "2. **Input Data:** Takes as input aligned reads in SAM (Sequence Alignment/Map) or BAM (Binary Alignment/Map) format, typically generated by aligners like HISAT2 or STAR.\n",
    "\n",
    "3. **Feature Annotation:** Requires a file containing annotations of genomic features, such as gene coordinates in GTF (Gene Transfer Format) or GFF (General Feature Format).\n",
    "\n",
    "4. **Counting Strategy:** Implements a strategy to assign aligned reads to features based on their alignment coordinates. Reads overlapping multiple features or features with overlapping coordinates can be handled according to specified preferences.\n",
    "\n",
    "5. **Output:** Produces a table or file containing the count of reads aligned to each feature, which can be used for downstream differential expression analysis or other gene expression studies.\n",
    "\n",
    "6. **Compatible with Downstream Tools:** The output of `htseq-count` is compatible with various statistical tools and workflows used for differential expression analysis, such as DESeq2 or edgeR.\n",
    "\n",
    "In summary, `htseq-count` is a valuable tool for quantifying gene expression from RNA-seq data, providing researchers with essential data for understanding the transcriptional landscape of biological samples.\n",
    "\n",
    "### Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be309597-5c52-4bde-885f-48c8b5ab94c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7659 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "444631 alignments  processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "317598 alignments  processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "334403 alignments  processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "295135 alignments  processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "492530 alignments  processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "276871 alignments  processed.\n"
     ]
    }
   ],
   "source": [
    "htseq-count -f bam -r pos -s no -t gene -i ID -m intersection-nonempty hisat2/*-sort.bam Data/O.tauri_annotation.gff > counts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297f7fc1-5f9d-477f-b699-a38a4af0bf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ostta01g00010\t11\t10\t10\t1\t4\t7\n",
      "ostta01g00020\t3\t7\t10\t6\t7\t5\n",
      "ostta01g00030\t0\t1\t1\t2\t0\t2\n",
      "ostta01g00040\t20\t13\t17\t23\t16\t12\n",
      "ostta01g00050\t5\t18\t8\t12\t13\t11\n",
      "ostta01g00060\t4\t2\t4\t5\t2\t7\n",
      "ostta01g00070\t2\t3\t4\t1\t1\t2\n",
      "ostta01g00080\t2\t2\t0\t0\t0\t0\n",
      "ostta01g00090\t17\t81\t61\t45\t61\t65\n",
      "ostta01g00100\t11\t14\t10\t5\t19\t8\n"
     ]
    }
   ],
   "source": [
    "head counts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2beb8cb-3ebe-484e-803b-337e4d5742a6",
   "metadata": {},
   "source": [
    "## Differential analysis\n",
    "\n",
    "### The tool we use : `Desq2`\n",
    "\n",
    "DESeq2 is a software package for differential gene expression analysis from RNA sequencing (RNA-seq) data. It is widely used in molecular biology and genomics to identify genes whose expression varies significantly between different experimental conditions.\n",
    "\n",
    "### Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b4b958-fe8d-45d4-bc99-35e4566462d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'Deseq2.ipynb' matched no files\n",
      "This application is used to convert notebook files (*.ipynb)\n",
      "        to various other formats.\n",
      "\n",
      "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
      "\n",
      "Options\n",
      "=======\n",
      "The options below are convenience aliases to configurable class-options,\n",
      "as listed in the \"Equivalent to\" description-line of the aliases.\n",
      "To see all configurable class-options for some <cmd>, use:\n",
      "    <cmd> --help-all\n",
      "\n",
      "--debug\n",
      "    set log level to logging.DEBUG (maximize logging output)\n",
      "    Equivalent to: [--Application.log_level=10]\n",
      "--show-config\n",
      "    Show the application's configuration (human-readable format)\n",
      "    Equivalent to: [--Application.show_config=True]\n",
      "--show-config-json\n",
      "    Show the application's configuration (json format)\n",
      "    Equivalent to: [--Application.show_config_json=True]\n",
      "--generate-config\n",
      "    generate default config file\n",
      "    Equivalent to: [--JupyterApp.generate_config=True]\n",
      "-y\n",
      "    Answer yes to any questions instead of prompting.\n",
      "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
      "--execute\n",
      "    Execute the notebook prior to export.\n",
      "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
      "--allow-errors\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
      "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
      "--stdin\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
      "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
      "--stdout\n",
      "    Write notebook output to stdout instead of files.\n",
      "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
      "--inplace\n",
      "    Run nbconvert in place, overwriting the existing notebook (only\n",
      "            relevant when converting to notebook format)\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
      "--clear-output\n",
      "    Clear output of current file and save in place,\n",
      "            overwriting the existing notebook.\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
      "--coalesce-streams\n",
      "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
      "--no-prompt\n",
      "    Exclude input and output prompts from converted document.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
      "--no-input\n",
      "    Exclude input cells and output prompts from converted document.\n",
      "            This mode is ideal for generating code-free reports.\n",
      "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
      "--allow-chromium-download\n",
      "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
      "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
      "--disable-chromium-sandbox\n",
      "    Disable chromium security sandbox when converting to PDF..\n",
      "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
      "--show-input\n",
      "    Shows code input. This flag is only useful for dejavu users.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
      "--embed-images\n",
      "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
      "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
      "--sanitize-html\n",
      "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
      "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
      "--log-level=<Enum>\n",
      "    Set the log level by value or name.\n",
      "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
      "    Default: 30\n",
      "    Equivalent to: [--Application.log_level]\n",
      "--config=<Unicode>\n",
      "    Full path of a config file.\n",
      "    Default: ''\n",
      "    Equivalent to: [--JupyterApp.config_file]\n",
      "--to=<Unicode>\n",
      "    The export format to be used, either one of the built-in formats\n",
      "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
      "            or a dotted object name that represents the import path for an\n",
      "            ``Exporter`` class\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.export_format]\n",
      "--template=<Unicode>\n",
      "    Name of the template to use\n",
      "    Default: ''\n",
      "    Equivalent to: [--TemplateExporter.template_name]\n",
      "--template-file=<Unicode>\n",
      "    Name of the template file to use\n",
      "    Default: None\n",
      "    Equivalent to: [--TemplateExporter.template_file]\n",
      "--theme=<Unicode>\n",
      "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
      "    as prebuilt extension for the lab template)\n",
      "    Default: 'light'\n",
      "    Equivalent to: [--HTMLExporter.theme]\n",
      "--sanitize_html=<Bool>\n",
      "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
      "    should be set to True by nbviewer or similar tools.\n",
      "    Default: False\n",
      "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
      "--writer=<DottedObjectName>\n",
      "    Writer class used to write the\n",
      "                                        results of the conversion\n",
      "    Default: 'FilesWriter'\n",
      "    Equivalent to: [--NbConvertApp.writer_class]\n",
      "--post=<DottedOrNone>\n",
      "    PostProcessor class used to write the\n",
      "                                        results of the conversion\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
      "--output=<Unicode>\n",
      "    Overwrite base name use for output files.\n",
      "                Supports pattern replacements '{notebook_name}'.\n",
      "    Default: '{notebook_name}'\n",
      "    Equivalent to: [--NbConvertApp.output_base]\n",
      "--output-dir=<Unicode>\n",
      "    Directory to write output(s) to. Defaults\n",
      "                                  to output to the directory of each notebook. To recover\n",
      "                                  previous default behaviour (outputting to the current\n",
      "                                  working directory) use . as the flag value.\n",
      "    Default: ''\n",
      "    Equivalent to: [--FilesWriter.build_directory]\n",
      "--reveal-prefix=<Unicode>\n",
      "    The URL prefix for reveal.js (version 3.x).\n",
      "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
      "            of reveal.js.\n",
      "            For speaker notes to work, this must be a relative path to a local\n",
      "            copy of reveal.js: e.g., \"reveal.js\".\n",
      "            If a relative path is given, it must be a subdirectory of the\n",
      "            current directory (from which the server is run).\n",
      "            See the usage documentation\n",
      "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
      "            for more details.\n",
      "    Default: ''\n",
      "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
      "--nbformat=<Enum>\n",
      "    The nbformat version to write.\n",
      "            Use this to downgrade notebooks.\n",
      "    Choices: any of [1, 2, 3, 4]\n",
      "    Default: 4\n",
      "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "    The simplest way to use nbconvert is\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to html\n",
      "\n",
      "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
      "\n",
      "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
      "\n",
      "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
      "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
      "            'classic'. You can specify the flavor of the format used.\n",
      "\n",
      "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
      "\n",
      "            You can also pipe the output to stdout, rather than a file\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
      "\n",
      "            PDF is generated via latex\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
      "\n",
      "            You can get (and serve) a Reveal.js-powered slideshow\n",
      "\n",
      "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
      "\n",
      "            Multiple notebooks can be given at the command line in a couple of\n",
      "            different ways:\n",
      "\n",
      "            > jupyter nbconvert notebook*.ipynb\n",
      "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
      "\n",
      "            or you can specify the notebooks list in a config file, containing::\n",
      "\n",
      "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
      "\n",
      "            > jupyter nbconvert --config mycfg.py\n",
      "\n",
      "To see all available configurables, use `--help-all`.\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "255",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "jupyter nbconvert --to script Deseq2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ec07fca-cc6b-4423-abf1-6c9825ce05da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: Deseq2.r: No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "R < Deseq2.r --no-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c9346-d231-4b66-b43e-5b0121aa798f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
